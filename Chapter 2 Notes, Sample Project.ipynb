{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 - End to End Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main steps you will go through in a machine learning project are as follows:<br>\n",
    "<br>\n",
    "1 Think about the big picture<br>\n",
    "2 Get your data<br> \n",
    "3 Discover and visualize data to gain insights<br>\n",
    "4 Prepare data for ML algorithms<br>\n",
    "5 Select a model and train it<br>\n",
    "6 Fine tune your model<br>\n",
    "7 Present your solution <br>\n",
    "8 Launch, monitor, and maintain your system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Look at the big picture\n",
    "\n",
    "It is crucial before beginning a project, especially if the task was given to you at a job, to understand what the system will be used for. It will be very difficult to create a system that correctly accomplishes what needs to be done if you do no know what the end goal is.<br>\n",
    "Once you understand what you are trying to accomplish, you need to figure out what type of problem it is. Is it supervised regession problem? Reinforcement learning? Unsupervised clustering? <br>\n",
    "After deciding the task you will implement, you need to find a way to measure your model's preformance. A typical supervised regression problem will use Root Mean Squared Error(RMSE)<br>\n",
    "\\begin{equation*}\n",
    "RMSE(X,h)= \\sqrt{\\frac{1}{m}\\sum_{i=1}^m (h(x^{(i)}))-y^{(i)})^2}\n",
    "\\end{equation*}\n",
    "\n",
    "We can also use the Mean Absolute Error\n",
    "\\begin{equation*}\n",
    "MAE(X,h) = \\frac{1}{m} \\sum_{i=1}^m |h(x^{(i)}) - y^{(i)}|\n",
    "\\end{equation*}\n",
    "\n",
    "These are just 2 of many ways we can measure preformance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the data\n",
    "\n",
    "Depending on where your data is coming from there are many different ways to retrieve and load your data. Before trying to load the data make sure you are familar with the layout scheme of the data. You then want to load your data into a dataframe to be able to use in python. Some nice ways to see bits of your dataframe data is by the following commands. <br>\n",
    "<br> \n",
    "- df.head()\n",
    "- df.tail()\n",
    "- df.info()\n",
    "<br>\n",
    "\n",
    "This is crucial to know what the data looks like because you might have to make further cleaning measures after, for example N/A values. It will also tell you if you are working with categorical or quantitative values. \n",
    "<br> \n",
    "<br>\n",
    "The **df.describe()** method will show you the summary statisitics on each column(variable) in your dataframe. <br><br>\n",
    "We can also use the **df.hist()** method to plot histograms of the numerical variables to see their distributions. <br><br>\n",
    "Once you have a brief idea abobut how our dataset looks we want to set aside a test set. We do this early on because we do not want to build asusmptions about the behavior of our dataset and pick specific models because of it. This will lead to an overly optimisitc generalization error(snooping bias).  <br><br>\n",
    "We can do this using **sklearn.model_selection** package **train_test_split** function.<br><br>\n",
    "\n",
    "When splittig your dataset up you want to make sure that you are not introducing sampling bias. We can do this by several measure, one is called *Stratified sampling* which breaks down your set into multiple subsets that is represenative of the total data. It then pulls data from each subset proportional to its whole dataset. <br><br>\n",
    "- Example: If test average height of country our sample would be skewed if it was filled with NBA players.\n",
    " <br><br>\n",
    " To do stratified sampling we can split our dataset using the **sklearn.model_selection** **StratifiedShuffleSplit** funciton. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Discover and Visualize the Data to Gain Insights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways we can now take our training set an analyze our data even further. One way is to run a scatter plot. A scatter plot can also tell use a lot about the correlation of a set of two variables. \n",
    "<br><br>\n",
    "We can even make a scatter plot matrix by the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "#scatter_matrix(df['column names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the variables are plotted against themselves the scatter matrix instead plots a histograms of that variable. \n",
    "<br><br>\n",
    "This is a more intuitive process. You can look at the data and try to clean/ alter it in ways you seem fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare the data for ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We you begin to transform your data you should make functions that way your work is reproducible and makes it easier for future work.<br><br>\n",
    "- It is important to clean your data so you do not have any missing values in it. ML Algos have a difficult time with missing values.<br><br>\n",
    "- You will want to consider scaling when your estimators vary significantly. You can do this by min-max scaling(normalization) or standardization.<br><br>\n",
    "- Normalization puts everything on a scale from 0 to 1.<br><br>\n",
    "- Standarization puts everything on a mean 0 scale.<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Select a model and train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up things will be much easier.All we neeed to do is pick a model<br><br>\n",
    "From the **sklearn.linear_model** package we can use the **LinearRegression** function to create the model and the **lin_reg.predict** method to create predicitons.<br><br>\n",
    "We can also get our RMSE from **sklearn.metrics** package by taking the square root of the mean_squared_error function output.<br><br>\n",
    "One could also decided to you the **DecisionTreeRegressor** function from the **sklearn.tree** package.<br><br>\n",
    "We can also split our data up into different batches using cross validation. This can be done by  **sklearn.model_selection** package and the **cross_val_score** function while the paramter *cv* specifies the number of folds.\n",
    "Be sure to save your models for later use using the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#to save\n",
    "#joblib.dump(my_model, 'mymodel.pkl')\n",
    "\n",
    "#to load\n",
    "#my_model_loaded = joblib.load('my_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fine-Tune your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " One way you can fiddle with your hyperparameters is by using the **GridSearchCV** in the **sklearn.model_selection** package to find the best combination of hyperparameters that you specified for it.<br><br>\n",
    " For models with much larger hyperparameter search space we can use **RandomSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze the Best Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the best model you can gain insight on what is the best and worst features oft he model. You could then try tweaking the model by possibly removing unneeded features.<br><br>\n",
    "Now we can finally evaluate our model on our test set, beware there will be no more tuning of your model after this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Launch, Monitor, Maintain your System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your model has launched you need to monitor it from breaking or degrading over time. <br><br>\n",
    "You will want to train your models on a regular basis as to not have degrading happen because of old data.<br><br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
